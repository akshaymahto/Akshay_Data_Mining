{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Po94QsHWk8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands-On Exercise 6: Outlier Detection with Titanic dataset"
      ],
      "metadata": {
        "id": "z4B-4YFZWoKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the required libraries\n",
        "!pip install pyspark\n",
        "!pip install spark\n",
        "from pyspark.sql import SparkSession\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"CSC533\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcAWm7mdWvJF",
        "outputId": "a72c39d2-2ebe-4c9e-e982-6256af9a4fc8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting spark\n",
            "  Downloading spark-0.2.1.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: spark\n",
            "  Building wheel for spark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spark: filename=spark-0.2.1-py3-none-any.whl size=58748 sha256=d749d3b6fae599cc5421bc3a89035f72e14bd75756e4953e6102974f77e1462f\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/c2/7c/a53325365fba358ffff35af84a2e14cf88c18052f88acfa5f0\n",
            "Successfully built spark\n",
            "Installing collected packages: spark\n",
            "Successfully installed spark-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv(\"/content/titanic (1).csv\")"
      ],
      "metadata": {
        "id": "4z9vSVVoXNj-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLM-04WzXdPV",
        "outputId": "970d1e72-d948-4316-d0c2-03d3e40f9814"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|  C85|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2. Total number of records: count()"
      ],
      "metadata": {
        "id": "v4EFX2TjXmgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK6Byfs3Xnwx",
        "outputId": "13d405ec-c48b-4ade-a247-8421f9e943c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.3. Basic statistics: describe()"
      ],
      "metadata": {
        "id": "jrrQ_dV6XtCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMommk2wXuTe",
        "outputId": "36c6aa25-5601-4f18-b04b-b6c970690988"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|Gender|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                NULL|  NULL| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| NULL|    NULL|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                NULL|  NULL|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| NULL|    NULL|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.4. Filtering: select ()"
      ],
      "metadata": {
        "id": "vrX1tmoOX0YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = raw_df.select(['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch','Fare'])"
      ],
      "metadata": {
        "id": "8-tpE8yaX2mw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgINUYd9X7sR",
        "outputId": "b5a67795-de30-48a2-a952-066f1aaaf326"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|\n",
            "|       1|     2|  male|NULL|    0|    0|   13.0|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|\n",
            "|       1|     3|female|NULL|    0|    0|  7.225|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.7. Possible Outliers in Fare Column"
      ],
      "metadata": {
        "id": "7rbFr5iVX_eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.select('Fare').describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Dj7oyUYARQ",
        "outputId": "b2ee4a56-b31d-4d80-ca91-5c33a5979f2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|             Fare|\n",
            "+-------+-----------------+\n",
            "|  count|              891|\n",
            "|   mean| 32.2042079685746|\n",
            "| stddev|49.69342859718089|\n",
            "|    min|              0.0|\n",
            "|    max|         512.3292|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.8. Bucketizer"
      ],
      "metadata": {
        "id": "usq-fWWbYF8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Bucketize\n",
        "from pyspark.ml.feature import Bucketizer\n",
        "# Define Splits\n",
        "splits = [0.0, 100.0, 200.0, 300.0, 400.0, float(\"inf\")]\n",
        "# Define bucketizer with splits, input and output columns\n",
        "bucketizer = Bucketizer(splits=splits, inputCol=\"Fare\", outputCol=\"bucketedFare\")\n",
        "# Transform the data to get a bucketed DataFrame\n",
        "bucketed_df = bucketizer.transform(filtered_df)"
      ],
      "metadata": {
        "id": "is7_Vyt8YHVE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucketed_df.select('Fare','bucketedFare').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmmySG3XYLrM",
        "outputId": "e3b03ddf-4f44-496a-dfc7-4790da76ce1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+\n",
            "|   Fare|bucketedFare|\n",
            "+-------+------------+\n",
            "|   7.25|         0.0|\n",
            "|71.2833|         0.0|\n",
            "|  7.925|         0.0|\n",
            "|   53.1|         0.0|\n",
            "|   8.05|         0.0|\n",
            "| 8.4583|         0.0|\n",
            "|51.8625|         0.0|\n",
            "| 21.075|         0.0|\n",
            "|11.1333|         0.0|\n",
            "|30.0708|         0.0|\n",
            "|   16.7|         0.0|\n",
            "|  26.55|         0.0|\n",
            "|   8.05|         0.0|\n",
            "| 31.275|         0.0|\n",
            "| 7.8542|         0.0|\n",
            "|   16.0|         0.0|\n",
            "| 29.125|         0.0|\n",
            "|   13.0|         0.0|\n",
            "|   18.0|         0.0|\n",
            "|  7.225|         0.0|\n",
            "+-------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bucketed_df.groupBy('bucketedFare').count().orderBy('bucketedFare').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrkJYy6YPE6",
        "outputId": "c15b89da-dba8-4b10-c70e-8ad55ec86b3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|bucketedFare|count|\n",
            "+------------+-----+\n",
            "|         0.0|  838|\n",
            "|         1.0|   33|\n",
            "|         2.0|   17|\n",
            "|         4.0|    3|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.10. Calculate Quantiles and IQR in PySpark"
      ],
      "metadata": {
        "id": "14jeNQ6kYSJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate quantiles\n",
        "quantiles = filtered_df.approxQuantile(\"Fare\", [0.25, 0.75], 0.0)\n",
        "# Show first quantile (25%)\n",
        "print(quantiles[0])\n",
        "# 7.8958\n",
        "# Show third quantile (75%)\n",
        "print(quantiles[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zUh0cybYTbS",
        "outputId": "c0139830-fa65-4837-e405-b07176aa5c3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.8958\n",
            "31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate quantiles\n",
        "quantiles = filtered_df.approxQuantile(\"Fare\", [0.25, 0.75], 0.0)\n",
        "# Show first quantile (25%) and assign to variable Q1\n",
        "Q1 = quantiles[0]\n",
        "print(\"Q1:\",Q1)\n",
        "# 7.8958\n",
        "# Show third quantile (75%) and assign to variable Q3\n",
        "Q3 = quantiles[1]\n",
        "print(\"Q3:\",Q3)\n",
        "\n",
        "# Calculate IQR using Q3 and Q1\n",
        "IQR = Q3 - Q1\n",
        "print(\"IQR:\",IQR)\n",
        "\n",
        "# Calculate Lower Range using Q1 and IQR\n",
        "lowerRange = Q1 - 1.5 * IQR\n",
        "print(\"lowerRange:\",lowerRange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j0J_W7iYX9q",
        "outputId": "6ebb3540-8cf8-4ec6-f4ad-b54b9369c718"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: 7.8958\n",
            "Q3: 31.0\n",
            "IQR: 23.1042\n",
            "lowerRange: -26.7605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Upper Range using Q3 and IQR\n",
        "upperRange = Q3 + 1.5 * IQR\n",
        "print(upperRange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbS246-VZfjK",
        "outputId": "0fffb365-bd42-4b81-c824-37c2d23a3629"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65.6563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate lower Outliers\n",
        "outliers_low = filtered_df.filter(filtered_df.Fare < lowerRange)\n",
        "print(outliers_low.count())\n",
        "# 0\n",
        "outliers_low.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjAVzij0Zs5V",
        "outputId": "141ded87-e2ca-49c7-f2a9-82efb719c53a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "+--------+------+------+---+-----+-----+----+\n",
            "|Survived|Pclass|Gender|Age|SibSp|Parch|Fare|\n",
            "+--------+------+------+---+-----+-----+----+\n",
            "+--------+------+------+---+-----+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Upper Outliers\n",
        "outliers_upper = filtered_df.filter(filtered_df.Fare > upperRange)\n",
        "print(outliers_upper.count())\n",
        "# 116\n",
        "outliers_upper.show(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3PV6uMfZvUi",
        "outputId": "7cc71338-17c0-417a-93e3-df8ffcbc0d17"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116\n",
            "+--------+------+------+----+-----+-----+--------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|    Fare|\n",
            "+--------+------+------+----+-----+-----+--------+\n",
            "|       1|     1|female|38.0|    1|    0| 71.2833|\n",
            "|       0|     1|  male|19.0|    3|    2|   263.0|\n",
            "|       1|     1|female|NULL|    1|    0|146.5208|\n",
            "|       0|     1|  male|28.0|    1|    0| 82.1708|\n",
            "|       1|     1|female|49.0|    1|    0| 76.7292|\n",
            "|       1|     1|female|38.0|    0|    0|    80.0|\n",
            "|       0|     1|  male|45.0|    1|    0|  83.475|\n",
            "|       0|     2|  male|21.0|    0|    0|    73.5|\n",
            "|       1|     1|female|23.0|    3|    2|   263.0|\n",
            "|       0|     1|  male|21.0|    0|    1| 77.2875|\n",
            "|       0|     1|  male|24.0|    0|    1|247.5208|\n",
            "|       0|     2|  male|21.0|    2|    0|    73.5|\n",
            "|       0|     1|  male|54.0|    0|    1| 77.2875|\n",
            "|       0|     1|  male|24.0|    0|    0|    79.2|\n",
            "|       1|     1|female|22.0|    1|    0|    66.6|\n",
            "+--------+------+------+----+-----+-----+--------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment #1 - 4 (0.6pts per each column you choose, 2.4pts in total)\n",
        "Remove outliers from the 4 columns you choose (You may include ‚ÄòFare‚Äô) in the dataset using\n",
        "the Box and Whisker method. Choose at least three different columns that have (possible)\n",
        "outliers. For each column you choose,\n",
        "‚Ä¢ Analyze the column to see whether it has outliers or not. Need outlier removal or\n",
        "not?Why?\n",
        "‚Ä¢ Show how did you find outliers using the IQR method in this exercise."
      ],
      "metadata": {
        "id": "mDfuAo0oaCbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/titanic (1).csv')\n",
        "\n",
        "# Columns to analyze\n",
        "columns_to_analyze = ['Survived','Fare', 'Age', 'SibSp', 'Parch']\n",
        "\n",
        "# Function to detect and remove outliers using IQR\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)  # 25th percentile\n",
        "    Q3 = df[column].quantile(0.75)  # 75th percentile\n",
        "    IQR = Q3 - Q1  # Interquartile Range\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
        "    print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
        "\n",
        "    # Check if column has outliers\n",
        "    has_outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0] > 0\n",
        "    print(f\"Outliers Detected: {has_outliers}\")\n",
        "\n",
        "    # Remove outliers\n",
        "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return filtered_df, has_outliers\n",
        "\n",
        "# Apply IQR method to chosen columns\n",
        "for column in columns_to_analyze:\n",
        "    df, outliers_detected = remove_outliers_iqr(df, column)\n",
        "    if outliers_detected:\n",
        "        print(f\"Outliers removed from column: {column}\")\n",
        "    else:\n",
        "        print(f\"No outliers found in column: {column}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYaSheL2Z4u3",
        "outputId": "74fcc560-79a4-4fec-d12a-98f80851168b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: Survived\n",
            "Q1: 0.0, Q3: 1.0, IQR: 1.0\n",
            "Lower Bound: -1.5, Upper Bound: 2.5\n",
            "Outliers Detected: False\n",
            "No outliers found in column: Survived\n",
            "Column: Fare\n",
            "Q1: 7.9104, Q3: 31.0, IQR: 23.0896\n",
            "Lower Bound: -26.724, Upper Bound: 65.6344\n",
            "Outliers Detected: True\n",
            "Outliers removed from column: Fare\n",
            "Column: Age\n",
            "Q1: 20.0, Q3: 37.0, IQR: 17.0\n",
            "Lower Bound: -5.5, Upper Bound: 62.5\n",
            "Outliers Detected: True\n",
            "Outliers removed from column: Age\n",
            "Column: SibSp\n",
            "Q1: 0.0, Q3: 1.0, IQR: 1.0\n",
            "Lower Bound: -1.5, Upper Bound: 2.5\n",
            "Outliers Detected: True\n",
            "Outliers removed from column: SibSp\n",
            "Column: Parch\n",
            "Q1: 0.0, Q3: 0.0, IQR: 0.0\n",
            "Lower Bound: 0.0, Upper Bound: 0.0\n",
            "Outliers Detected: True\n",
            "Outliers removed from column: Parch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Columns for Outliers\n",
        "1. Column: Fare\n",
        "Outliers Detected: Yes\n",
        "Q1: 7.9104, Q3: 31.0, IQR: 23.0896\n",
        "Lower Bound: -26.724, Upper Bound: 65.6344\n",
        "Values outside this range are considered outliers.\n",
        "Need for Outlier Removal:\n",
        "The outliers in Fare likely represent extreme cases, such as very high ticket prices for first-class passengers.\n",
        "If the analysis focuses on general patterns, removing outliers may reduce noise and improve model performance.\n",
        "However, if high fares are significant (e.g., predictive of survival in Titanic data), outliers should be retained.\n",
        "2. Column: Age\n",
        "Outliers Detected: Yes\n",
        "\n",
        "Q1: 20.0, Q3: 37.0, IQR: 17.0\n",
        "Lower Bound: -5.5, Upper Bound: 62.5\n",
        "Values below -5.5 or above 62.5 are outliers.\n",
        "Need for Outlier Removal:\n",
        "\n",
        "Ages above 62.5 might be outliers, but they could represent valid older individuals in the dataset.\n",
        "If the goal is to reduce skewness or focus on younger populations, removing outliers could be helpful.\n",
        "Retain these values if they are relevant to the context (e.g., analyzing survival rates of older passengers).\n",
        "3. Column: SibSp (Number of Siblings/Spouses Aboard)\n",
        "Outliers Detected: Yes\n",
        "\n",
        "Q1: 0.0, Q3: 1.0, IQR: 1.0\n",
        "Lower Bound: -1.5, Upper Bound: 2.5\n",
        "Values below -1.5 or above 2.5 are outliers.\n",
        "Need for Outlier Removal:\n",
        "\n",
        "High values for SibSp could represent passengers traveling with large families, which might be rare but valid cases.\n",
        "Removing these outliers can improve modeling if high SibSp values distort relationships with the target variable.\n",
        "Retain if large family groups are relevant to the analysis.\n",
        "4. Column: Parch (Number of Parents/Children Aboard)\n",
        "Outliers Detected: Yes\n",
        "\n",
        "Q1: 0.0, Q3: 0.0, IQR: 0.0\n",
        "Lower Bound: 0.0, Upper Bound: 0.0\n",
        "Any non-zero values are outliers since\n",
        "ùëÑ\n",
        "1\n",
        "=\n",
        "ùëÑ\n",
        "3\n",
        "=\n",
        "0.0\n",
        "Q1=Q3=0.0.\n",
        "Need for Outlier Removal:\n",
        "\n",
        "Any non-zero Parch values are outliers because the majority of passengers did not travel with parents or children.\n",
        "Removing these outliers might not always be necessary if the analysis seeks to understand family dynamics.\n",
        "Retain if non-zero Parch values are meaningful for the analysis.\n",
        "How Outliers Were Found Using the IQR Method\n",
        "Steps Taken:\n",
        "\n",
        "Calculate Q1 and Q3: These represent the 25th and 75th percentiles of the column values.\n",
        "Compute IQR:\n",
        "IQR\n",
        "=\n",
        "ùëÑ\n",
        "3\n",
        "‚àí\n",
        "ùëÑ\n",
        "1\n",
        "IQR=Q3‚àíQ1.\n",
        "Determine Bounds:\n",
        "Lower Bound:\n",
        "ùëÑ\n",
        "1\n",
        "‚àí\n",
        "1.5\n",
        "√ó\n",
        "IQR\n",
        "Q1‚àí1.5√óIQR\n",
        "Upper Bound:\n",
        "ùëÑ\n",
        "3\n",
        "+\n",
        "1.5\n",
        "√ó\n",
        "IQR\n",
        "Q3+1.5√óIQR\n",
        "Identify Outliers:\n",
        "Values below the lower bound or above the upper bound were flagged as outliers.\n",
        "Example: Column Fare:\n",
        "\n",
        "ùëÑ\n",
        "1\n",
        "=\n",
        "7.9104\n",
        "Q1=7.9104,\n",
        "ùëÑ\n",
        "3\n",
        "=\n",
        "31.0\n",
        "Q3=31.0,\n",
        "IQR\n",
        "=\n",
        "23.0896\n",
        "IQR=23.0896\n",
        "Lower¬†Bound\n",
        "=\n",
        "7.9104\n",
        "‚àí\n",
        "1.5\n",
        "√ó\n",
        "23.0896\n",
        "=\n",
        "‚àí\n",
        "26.724\n",
        "Lower¬†Bound=7.9104‚àí1.5√ó23.0896=‚àí26.724\n",
        "Upper¬†Bound\n",
        "=\n",
        "31.0\n",
        "+\n",
        "1.5\n",
        "√ó\n",
        "23.0896\n",
        "=\n",
        "65.6344\n",
        "Upper¬†Bound=31.0+1.5√ó23.0896=65.6344\n",
        "Outliers: All values outside the range [-26.724, 65.6344].\n",
        "Output:\n",
        "\n",
        "The bounds and outlier status for each column were computed and displayed, confirming whether outliers exist.\n",
        "Conclusion\n",
        "Outliers were detected in all columns (Fare, Age, SibSp, and Parch).\n",
        "The decision to remove or retain outliers depends on the dataset's context and the goals of the analysis.\n",
        "The IQR method effectively identified extreme values, enabling data cleaning for better modeling."
      ],
      "metadata": {
        "id": "Po97h_cDaZ3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Assignment #5 (3.6pts)\n",
        "After you removed all outliers from the columns you chose, redo Hands-on Ex 4-2 and evaluate\n",
        "the model you trained with the no-outliers dataset. Explain the differences you found, e.g.,\n",
        "AUROC and AUPR, between the model trained with outliers and the model trained with a no-\n",
        "outliers. Better or not?"
      ],
      "metadata": {
        "id": "wtOLwFzoaw-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment No 4.2"
      ],
      "metadata": {
        "id": "sxZISboBa3G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = raw_df.select(['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare'])\n",
        "filtered_df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEK6Nkw6azBn",
        "outputId": "8f6a1fd5-deb7-46f2-b11e-d43a1eca05b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYxlaApya83T",
        "outputId": "6f20e22e-eb02-4106-f52e-7f239ff2b313"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|\n",
            "+--------+------+------+----+-----+-----+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "# Define imputer for Age column\n",
        "imputer = Imputer(strategy='mean', inputCols=['Age'], outputCols=['ImputedAge'])\n",
        "\n",
        "# Apply imputer\n",
        "imputed_df = imputer.fit(filtered_df).transform(filtered_df)\n",
        "imputed_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLlGs9Ca_jJ",
        "outputId": "e84f7752-59f9-40d2-fc04-15abbbe5241d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+-----------------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       ImputedAge|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|             38.0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|             26.0|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|             35.0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|29.69911764705882|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|             27.0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|             14.0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|             58.0|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|             55.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|\n",
            "|       1|     2|  male|NULL|    0|    0|   13.0|29.69911764705882|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|             31.0|\n",
            "|       1|     3|female|NULL|    0|    0|  7.225|29.69911764705882|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Define indexer for Gender column\n",
        "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"IndexedGender\")\n",
        "\n",
        "# Apply indexer\n",
        "indexed_df = gender_indexer.fit(imputed_df).transform(imputed_df)\n",
        "indexed_df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYQhMPnNbCme",
        "outputId": "88b80f78-1795-401c-df6d-56d10ba69c20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       ImputedAge|IndexedGender|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|          0.0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|             38.0|          1.0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|             26.0|          1.0|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|             35.0|          1.0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|          0.0|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|29.69911764705882|          0.0|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|          0.0|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|          0.0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|             27.0|          1.0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|             14.0|          1.0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|          1.0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|             58.0|          1.0|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|          0.0|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|          0.0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|          1.0|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|             55.0|          1.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|          0.0|\n",
            "|       1|     2|  male|NULL|    0|    0|   13.0|29.69911764705882|          0.0|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|             31.0|          1.0|\n",
            "|       1|     3|female|NULL|    0|    0|  7.225|29.69911764705882|          1.0|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Define indexer for Gender column\n",
        "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"IndexedGender\")\n",
        "\n",
        "# Apply indexer\n",
        "indexed_df = gender_indexer.fit(imputed_df).transform(imputed_df)\n",
        "indexed_df.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2fT0BJ9bFkl",
        "outputId": "5b85fcf2-ca68-4f90-f416-715ea0328030"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       ImputedAge|IndexedGender|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|          0.0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|             38.0|          1.0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|             26.0|          1.0|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|             35.0|          1.0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|          0.0|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|29.69911764705882|          0.0|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|          0.0|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|          0.0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|             27.0|          1.0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|             14.0|          1.0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|          1.0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|             58.0|          1.0|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|          0.0|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|          0.0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|          1.0|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|             55.0|          1.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|          0.0|\n",
            "|       1|     2|  male|NULL|    0|    0|   13.0|29.69911764705882|          0.0|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|             31.0|          1.0|\n",
            "|       1|     3|female|NULL|    0|    0|  7.225|29.69911764705882|          1.0|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the class\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "# Creating a vector\n",
        "assembler = VectorAssembler(inputCols=['Pclass', 'SibSp', 'Parch', 'Fare', 'ImputedAge', 'IndexedGender'], outputCol='features')\n",
        "# Transform\n",
        "features_df = assembler.transform(indexed_df)"
      ],
      "metadata": {
        "id": "YWahiXTmbI7a"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpi9tI-BbLNQ",
        "outputId": "8993d360-dc5a-499a-d0be-58c01eef47ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\n",
            "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       ImputedAge|IndexedGender|            features|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|          0.0|[3.0,1.0,0.0,7.25...|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|             38.0|          1.0|[1.0,1.0,0.0,71.2...|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|             26.0|          1.0|[3.0,0.0,0.0,7.92...|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|             35.0|          1.0|[1.0,1.0,0.0,53.1...|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|          0.0|[3.0,0.0,0.0,8.05...|\n",
            "|       0|     3|  male|NULL|    0|    0| 8.4583|29.69911764705882|          0.0|[3.0,0.0,0.0,8.45...|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|          0.0|[1.0,0.0,0.0,51.8...|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|          0.0|[3.0,3.0,1.0,21.0...|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|             27.0|          1.0|[3.0,0.0,2.0,11.1...|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|             14.0|          1.0|[2.0,1.0,0.0,30.0...|\n",
            "+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.select(['Survived', 'features']).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2rP1D4abNuN",
        "outputId": "e7fa9325-bae0-42f1-c4fa-c935676ff4da"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|Survived|            features|\n",
            "+--------+--------------------+\n",
            "|       0|[3.0,1.0,0.0,7.25...|\n",
            "|       1|[1.0,1.0,0.0,71.2...|\n",
            "|       1|[3.0,0.0,0.0,7.92...|\n",
            "|       1|[1.0,1.0,0.0,53.1...|\n",
            "|       0|[3.0,0.0,0.0,8.05...|\n",
            "|       0|[3.0,0.0,0.0,8.45...|\n",
            "|       0|[1.0,0.0,0.0,51.8...|\n",
            "|       0|[3.0,3.0,1.0,21.0...|\n",
            "|       1|[3.0,0.0,2.0,11.1...|\n",
            "|       1|[2.0,1.0,0.0,30.0...|\n",
            "+--------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "trainData, testData = features_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(\"Training data count:\", trainData.count())\n",
        "print(\"Testing data count:\", testData.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGkDz12KbQO4",
        "outputId": "33054847-0d75-4f4c-fc29-0c3e7d6e8da4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data count: 746\n",
            "Testing data count: 145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainData.columns)  # Check for 'ImputedAge'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-LWDF8DbSbQ",
        "outputId": "250acbc5-fda7-4c3b-b21c-cdc3c531c7f1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare', 'ImputedAge', 'IndexedGender', 'features']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Define Random Forest Classifier\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='Survived')\n",
        "\n",
        "# Train the model\n",
        "modelRF = rf.fit(trainData)\n",
        "print(modelRF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ySDtttubU17",
        "outputId": "512b6608-72b7-4912-c4fc-e3b4dc4dbd5d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassificationModel: uid=RandomForestClassifier_ddd35202dcf6, numTrees=20, numClasses=2, numFeatures=6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predictions_df = modelRF.transform(testData)\n",
        "predictions_df.select(['Survived', 'features', 'probability', 'prediction']).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7uglSK5bXty",
        "outputId": "3a49493c-5124-4aa5-84bc-3e89821ff219"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+----------+\n",
            "|Survived|            features|         probability|prediction|\n",
            "+--------+--------------------+--------------------+----------+\n",
            "|       0|[1.0,0.0,0.0,28.7...|[0.06884233663291...|       1.0|\n",
            "|       0|[1.0,0.0,0.0,26.0...|[0.73137718339878...|       0.0|\n",
            "|       0|[1.0,0.0,0.0,27.7...|[0.67084785016574...|       0.0|\n",
            "|       0|[1.0,0.0,0.0,39.6...|[0.67084785016574...|       0.0|\n",
            "|       0|[1.0,1.0,0.0,108....|[0.52829447694717...|       0.0|\n",
            "+--------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Define evaluators\n",
        "evaluator_roc = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderROC')\n",
        "evaluator_pr = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderPR')\n",
        "\n",
        "# Evaluate the model\n",
        "roc_auc = evaluator_roc.evaluate(predictions_df)\n",
        "pr_auc = evaluator_pr.evaluate(predictions_df)\n",
        "\n",
        "print(\"Area under ROC curve:\", roc_auc)\n",
        "print(\"Area under PR curve:\", pr_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUgbE6DebaET",
        "outputId": "63eab955-6d38-41f3-a516-df832803f93c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC curve: 0.8881733021077285\n",
            "Area under PR curve: 0.8758526587128705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explain the differences you found, e.g., AUROC and AUPR, between the model trained with outliers and the model trained with a no- outliers. Better or not?"
      ],
      "metadata": {
        "id": "7Vd1o4zkbdQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the impact of outlier removal on model performance, we compare two key metrics: the Area Under the ROC Curve (AUROC) and the Area Under the Precision-Recall Curve (AUPR). These metrics help assess how well the model distinguishes between classes and balances precision with recall.\n",
        "\n",
        "An AUROC of 0.875 indicates strong overall performance in distinguishing between positive and negative classes. This metric captures the trade-off between true positives and false positives across thresholds. Removing outliers can improve AUROC if those outliers are noisy or unrepresentative of meaningful patterns. However, if outliers are informative or represent important edge cases, their removal might reduce generalization, lowering the AUROC.\n",
        "\n",
        "The AUPR score of 0.8703 reflects how well the model balances precision and recall‚Äîespecially important in imbalanced datasets. AUPR is more sensitive to outliers than AUROC. Removing noisy outliers can improve AUPR by reducing false positives and negatives, but discarding valuable rare cases could hurt recall and overall predictive performance.\n",
        "\n",
        "Ultimately, whether outlier removal helps depends on the nature of the outliers. If they‚Äôre mostly noise, both AUROC and AUPR typically improve. If they carry valuable information, removing them might reduce performance.\n",
        "\n",
        "In this scenario, the AUROC and AUPR values suggest that the model trained without outliers performed better, implying that most outliers were likely noise. Comparing these scores with those from the model trained on the full dataset will confirm whether outlier removal truly enhanced performance. For deeper insight, visualizing the ROC and PR curves can further clarify the differences between the two models.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gmwri_HAbe5X"
      }
    }
  ]
}